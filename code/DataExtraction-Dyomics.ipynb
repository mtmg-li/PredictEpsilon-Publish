{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UV8goW1kGMP1"
   },
   "source": [
    "# Dyomics data scrape notebook\n",
    "\n",
    "## Purpose and Context\n",
    "\n",
    "This notebook will extract data from the Dyomics product pdf, combine it with the SMILES data and store the data into a parquet format\n",
    "\n",
    "Go to https://dyomics.com/ for information\n",
    "\n",
    "Note: This notebook has a debug information displayed at each step to help fix any PDF parsing errors\n",
    "\n",
    "## Setup\n",
    "\n",
    "import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import utils\n",
    "\n",
    "import re\n",
    "from io import StringIO\n",
    "\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfdocument import PDFDocument\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.pdfparser import PDFParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "### Process PDF\n",
    "\n",
    "Getting text for each page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetPageText(page, resourceManager):\n",
    "    result = StringIO()\n",
    "    converter = TextConverter(resourceManager, result, laparams=LAParams(boxes_flow=1,char_margin=1000, line_margin=10, detect_vertical=True, all_texts=False))\n",
    "    PDFPageInterpreter(resourceManager, converter).process_page(page)\n",
    "\n",
    "    return result.getvalue()\n",
    "\n",
    "pagesRaw = []\n",
    "with open('../rawData/Dyomics/Dyomics_2017.pdf', 'rb') as in_file:\n",
    "    resourceManager = PDFResourceManager()\n",
    "\n",
    "    count = 0\n",
    "    for page in PDFPage.create_pages(PDFDocument(PDFParser(in_file))):\n",
    "        pageText = GetPageText(page, resourceManager)\n",
    "        pagesRaw.append({'page number': count, 'id': page.pageid, 'page text': pageText})\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting Dye Information on for each page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetDyeInformationText(text):\n",
    "    dyeInformation = re.split('(.+)\\n(?=Absorption.+)', text)\n",
    "    if (len(dyeInformation) == 1):\n",
    "        return None\n",
    "\n",
    "    results = []\n",
    "\n",
    "    print(dyeInformation)\n",
    "    for i in range(1, len(dyeInformation), 2):\n",
    "        results.append([dyeInformation[i], dyeInformation[i + 1]])\n",
    "\n",
    "    return results\n",
    "\n",
    "pages = pd.DataFrame(pagesRaw)\n",
    "pages['dye information text list'] = pages['page text'].apply(GetDyeInformationText)\n",
    "pages.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since a page can have multiple dyes on each page and some can have no dye information, splitting them out into their on rows to work on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pages[pages['dye information text list'].isnull() == False]['dye information text list']\\\n",
    "    .apply(lambda x: pd.Series(x))\\\n",
    "    .stack()\\\n",
    "    .reset_index(level = 1, drop = True)\\\n",
    "    .apply(lambda x: pd.Series(x))\\\n",
    "    .rename(columns = {0:'name', 1: 'dye information text'})\\\n",
    "    .join(pages)\\\n",
    "    .reset_index(drop = True)\n",
    "    \n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Breaking out the dye information text into is various chunks to make it easier to process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def BreakOutTextChunks(dyeText):\n",
    "    dyeText = dyeText.strip()\n",
    "    result = {}\n",
    "    temp = re.search('^Absorption/emission max.+\\n', dyeText)\n",
    "    if (temp):\n",
    "        result['absorption text'] = temp.group(0).strip()\n",
    "    else: # Handling page 91's different format\n",
    "        temp = re.search('^Absorption max.+\\n(Emission max.+)*', dyeText)\n",
    "        result['absorption text'] = temp.group(0).strip()\n",
    "    \n",
    "    dyeText = dyeText.replace(result['absorption text'], '').strip()\n",
    "    temp = re.search('^Molar absorbance.+\\n', dyeText)\n",
    "    result['molar absorbance text'] = temp.group(0).strip()\n",
    "    dyeText = dyeText.replace(result['molar absorbance text'], '').strip()\n",
    "\n",
    "    temp = re.search('.+Productnumber.*\\n', dyeText)\n",
    "    tableHeader = temp.group(0).strip()\n",
    "    temp = dyeText.split(tableHeader)\n",
    "    result['comments text'] = temp[0].strip()\n",
    "    result['table information text'] = temp[1].strip()\n",
    "\n",
    "    return result\n",
    "\n",
    "data = data['dye information text'].apply(BreakOutTextChunks)\\\n",
    "    .apply(lambda x: pd.Series(x))\\\n",
    "    .join(data)\n",
    "\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing absorption text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetAbsorptions(absorptionText):\n",
    "    temp = re.search('([0-9]+)[^0-9]+([0-9]+) nm (.+)', absorptionText)\n",
    "\n",
    "    result = {}\n",
    "    \n",
    "    if (temp):\n",
    "        result['absorption'] = temp.group(1)\n",
    "        result['emission max'] = temp.group(2)\n",
    "        result['solution'] = temp.group(3)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    temp = re.search('([0-9]+) nm (.+)', absorptionText)\n",
    "    if (temp):\n",
    "        result['absorption'] = temp.group(1)\n",
    "        result['solution'] = temp.group(2)\n",
    "        result['emission max'] = '0'\n",
    "    else:\n",
    "        result['absorption'] = result['emission max'] =  result['solution'] = 'Error'\n",
    "    \n",
    "\n",
    "    return result\n",
    "\n",
    "data = data['absorption text'].apply(GetAbsorptions)\\\n",
    "    .apply(lambda x: pd.Series(x))\\\n",
    "    .join(data)\n",
    "\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process molar absorbance text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetMolarAbsorbance(molarAbsorbanceText):\n",
    "    return re.search('(([0-9]|,)+)', molarAbsorbanceText).group(0)\n",
    "\n",
    "data['molar absorbance'] = data['molar absorbance text'].apply(GetMolarAbsorbance)\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing the dye table text\n",
    "\n",
    "Start by splitting out it's lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data['table information text'].apply(lambda x: x.splitlines())\\\n",
    "    .apply(lambda x: pd.Series(x))\\\n",
    "    .stack()\\\n",
    "    .reset_index(level = 1, drop = True)\\\n",
    "    .to_frame('table information row text')\\\n",
    "    .join(data)\\\n",
    "    .reset_index(drop = True)\n",
    "\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def GetWeight(line):\n",
    "    if (len(line) <= 10):\n",
    "        return 'Error: Short string found'\n",
    "\n",
    "    weightText = re.search('([0-9]+\\.[0-9]+)', line)\n",
    "    if (weightText == None):\n",
    "        if (re.search('^[^0-9]+$', line)):\n",
    "            return 'Error: Label found'\n",
    "        \n",
    "        if (re.search('^[A-Z]*([0-9]| |,)+$', line)):\n",
    "            return'Error: Graph axis found'\n",
    "        \n",
    "        if (re.search('[0-9]+nm', line)):\n",
    "            return 'Error: Label found'\n",
    "        \n",
    "        return 'Error: No weight found' \n",
    "    \n",
    "    return weightText.group(0)\n",
    "\n",
    "def GetTableRowInformation(tableInformationRow):\n",
    "    result = {}\n",
    "    result['weight'] = GetWeight(tableInformationRow)\n",
    "    \n",
    "    if ('Error' in result['weight']):\n",
    "        return result\n",
    "    \n",
    "    temp = tableInformationRow.split(result['weight'])\n",
    "    result['available modification'] = temp[0].strip()\n",
    "\n",
    "    t = re.split('([^\\s]+)', temp[1])\n",
    "    result['product number'] = t[len(t) - 2]\n",
    "    \n",
    "    result['formula'] = temp[1].replace(result['product number'], '').strip()\n",
    "\n",
    "    return result\n",
    "\n",
    "data = data['table information row text'].apply(GetTableRowInformation)\\\n",
    "    .apply(lambda x: pd.Series(x))\\\n",
    "    .join(data)\n",
    "\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually fixing MitoDy-1 on page 91's since it's format is messed up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping MitoDy-1 that have errors since one row is correct except for the product number and formula\n",
    "data = data[(data['name'] != 'MitoDy-1') | ((data['name'] == 'MitoDy-1') & (data['weight'].str.contains('Error') == False))]\n",
    "\n",
    "# Fixing product number\n",
    "mask = data['name'] == 'MitoDy-1'\n",
    "data.loc[mask, 'product number'] = 'MTD-1'\n",
    "data.loc[mask, 'formula'] = 'C21H25N2O3 * BF4'\n",
    "\n",
    "# Fixing some spaces in names\n",
    "data['name'] = data['name'].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any unhandled errors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (len(data[data['weight'] == 'Error: No weight found']) != 0):\n",
    "    raise 'new unhandled errors found'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping rows that errors that were handled already, so don't have useful information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[(data['weight'].str.contains('Error') == False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spot Checking to see if anything looks odd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.InspectColumnValues(data[['available modification', 'product number', 'formula', 'weight']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['product number', 'formula', 'weight', 'molar absorbance', 'emission max']:\n",
    "    print('All values for ' + column)\n",
    "    \n",
    "    print(data[column].unique())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing looks odd\n",
    "\n",
    "Removing pdf processing fields since it's no longer needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(data.columns[data.columns.str.contains(' text')], axis = 'columns', inplace = True)\n",
    "data.drop(['page number', 'id'], axis = 'columns', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine with the Smiles Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_csv('../rawData/Dyomics/SmilesData.csv')\n",
    "temp['Name'] = temp['Name'].str.upper()\n",
    "temp['Smiles'] = temp['Correct Smiles'].fillna(temp['Generated Smiles'])\n",
    "temp = temp[['Name', 'Smiles']]\n",
    "temp\n",
    "\n",
    "data = data.merge(temp, left_on = 'name', right_on = 'Name')\n",
    "data.drop(['Name'], axis = 'columns', inplace = True)\n",
    "print('Total Count: ' + str(len(data)))\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning up data, converting strings to int/float data type and compressing integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.columns = data.columns.str.replace('_', ' ').str.title()\n",
    "utils.DropAllNullColumns(data)\n",
    "utils.ConvertStringColumnsToInt(data)\n",
    "utils.ConvertStringColumnsToFloat(data)\n",
    "utils.CompressIntegerColumns(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.InspectColumnValues(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.ShowHistogramCharts(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving data for use later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.SaveDataToOutput(data, 'extraction-dyomics')\n",
    "utils.LoadDataFromOutput('extraction-dyomics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNaRjtgyXFTP8JqrVitcXbm",
   "collapsed_sections": [],
   "name": "Dyomics_Data_Extraction.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
